{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What are the three stages to build the hypotheses or model in machine learning?\n",
    "\n",
    "The three stages to build the hypothesis or model in machine learning are:\n",
    "\n",
    "a) Model building \n",
    "b) Model testing \n",
    "c) Applying the model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What is the standard approach to supervised learning?\n",
    "\n",
    "The standard approach to supervised learning is to split the set of example into the training set and the test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What is Training set and Test set?\n",
    "\n",
    "Training Set:\n",
    "Training set is a dataset used to train a model. In training the model, specific featuresare picked out from the training set. These features are then incorporated into the model. Thereby, if the training set is labeled correctly, the model should be able to learn something from these features.\n",
    "\n",
    "Test Set:\n",
    "\n",
    "The test set is a dataset used to measure how well the model performs at making predictions on that test set.\n",
    "If the prediction scores for the test set are unreasonable, weâ€™ll need to make some adjustments to our model\n",
    "and try again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What is the general principle of an ensemble method and what is bagging and  boosting in ensemble method?\n",
    "The general principle of an ensemble method is to combine the predictions of several models built with a given learning algorithm in order to improve robustness over a single model.\n",
    "-> Bagging is a method in ensemble for improving unstable estimation or classification schemes.\n",
    "-> Boosting provides sequential learning of the predictors. The first predictor is learned on the whole data set, while the    following are learnt on the training set based on the performance of the previous one.Boosting has shown better predictive accuracy than bagging, but it also tends to over-fit the training data as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. How can you avoid overfitting ?\n",
    "\n",
    "Steps for reducing overfitting:\n",
    "->. Add more data.\n",
    "->. Use data augmentation.\n",
    "->Use architectures that generalize well.\n",
    "->Add regularization (mostly dropout, L1/L2 regularization are also possible)\n",
    "->Reduce architecture complexity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
